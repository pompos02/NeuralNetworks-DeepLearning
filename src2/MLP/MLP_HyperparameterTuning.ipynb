{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20e212f8630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # Should print a version number if CUDA is supported\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = cifar10.load_data()\n",
    "\n",
    "# Flatten label arrays\n",
    "y_train_full = y_train_full.flatten()\n",
    "y_test_full = y_test_full.flatten()\n",
    "\n",
    "# Define the classes (cats and dogs)\n",
    "class_map = {5: 'dog', 3: 'cat'}\n",
    "\n",
    "# Filter training data\n",
    "train_filter = np.isin(y_train_full, list(class_map.keys()))\n",
    "x_train = x_train_full[train_filter]\n",
    "y_train = y_train_full[train_filter]\n",
    "\n",
    "# Filter test data\n",
    "test_filter = np.isin(y_test_full, list(class_map.keys()))\n",
    "x_test = x_test_full[test_filter]\n",
    "y_test = y_test_full[test_filter]\n",
    "\n",
    "# Map labels to +1 and -1\n",
    "label_map = {5: 1, 3: -1}\n",
    "y_train = np.vectorize(label_map.get)(y_train)\n",
    "y_test = np.vectorize(label_map.get)(y_test)\n",
    "\n",
    "# Flatten the images (32x32x3 -> 3072)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Convert to float32\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "x_test_tensor = torch.tensor(x_test)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HingeLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, outputs, labels):\n",
    "        outputs = outputs.view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        loss = torch.mean(torch.clamp(1 - outputs * labels, min=0))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs=30, device='cpu'):\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            predictions = torch.sign(outputs).view(-1)\n",
    "            correct += (predictions == labels.view(-1)).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / total\n",
    "        accuracy = correct / total\n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(accuracy)\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        model.eval()\n",
    "        total_loss_test = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs_test, labels_test in test_loader:\n",
    "                inputs_test, labels_test = inputs_test.to(device), labels_test.to(device)\n",
    "                outputs_test = model(inputs_test)\n",
    "                loss_test = criterion(outputs_test, labels_test)\n",
    "                total_loss_test += loss_test.item() * inputs_test.size(0)\n",
    "                predictions_test = torch.sign(outputs_test).view(-1)\n",
    "                correct_test += (predictions_test == labels_test.view(-1)).sum().item()\n",
    "                total_test += labels_test.size(0)\n",
    "        \n",
    "        avg_loss_test = total_loss_test / total_test\n",
    "        accuracy_test = correct_test / total_test\n",
    "        test_losses.append(avg_loss_test)\n",
    "        test_accuracies.append(accuracy_test)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}, Train Acc: {accuracy*100:.2f}%, Test Loss: {avg_loss_test:.4f}, Test Acc: {accuracy_test*100:.2f}%\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_outputs = model(x_train_tensor.to(device))\n",
    "        train_predictions = torch.sign(train_outputs).view(-1)\n",
    "        train_labels = y_train_tensor.view(-1).to(device)\n",
    "        train_accuracy = (train_predictions == train_labels).sum().item() / train_labels.size(0)\n",
    "        \n",
    "        test_outputs = model(x_test_tensor.to(device))\n",
    "        test_predictions = torch.sign(test_outputs).view(-1)\n",
    "        test_labels = y_test_tensor.view(-1).to(device)\n",
    "        test_accuracy = (test_predictions == test_labels).sum().item() / test_labels.size(0)\n",
    "    \n",
    "    print(f\"\\nFinal Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "    print(f\"Final Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'final_train_acc': train_accuracy,\n",
    "        'final_test_acc': test_accuracy\n",
    "    }\n",
    "\n",
    "# Define hyperparameter space\n",
    "hyperparameter_space = {\n",
    "    'learning_rate': [ 0.01, 0.001, 0.0001],\n",
    "    'hidden_size': [128, 256, 512],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'optimizer': ['SGD', 'Adam'],\n",
    "    'num_epochs': [30]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_search(hyperparameter_space, num_iterations=20, device='cpu'):\n",
    "    results = []\n",
    "    keys = list(hyperparameter_space.keys())\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Sample a random hyperparameter combination\n",
    "        sampled_params = {k: random.choice(v) for k, v in hyperparameter_space.items()}\n",
    "        print(f\"\\nRunning iteration {i+1}/{num_iterations} with parameters: {sampled_params}\")\n",
    "        \n",
    "        # Unpack hyperparameters\n",
    "        learning_rate = sampled_params['learning_rate']\n",
    "        hidden_size = sampled_params['hidden_size']\n",
    "        batch_size = sampled_params['batch_size']\n",
    "        optimizer_type = sampled_params['optimizer']\n",
    "        num_epochs = sampled_params['num_epochs']\n",
    "        \n",
    "        # Create DataLoaders with the current batch size\n",
    "        train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model\n",
    "        input_size = x_train_tensor.shape[1]\n",
    "        model = MLP(input_size, hidden_size)\n",
    "        \n",
    "        # Define loss and optimizer\n",
    "        criterion = HingeLoss()\n",
    "        if optimizer_type == 'SGD':\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        elif optimizer_type == 'Adam':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer type: {optimizer_type}\")\n",
    "        \n",
    "        # Train the model\n",
    "        metrics = train_model(model, criterion, optimizer, train_loader, test_loader, num_epochs=num_epochs, device=device)\n",
    "        \n",
    "        # Save results\n",
    "        results.append({\n",
    "            'params': sampled_params,\n",
    "            'final_train_acc': metrics['final_train_acc'],\n",
    "            'final_test_acc': metrics['final_test_acc']\n",
    "        })\n",
    "    \n",
    "    # Sort results by test accuracy\n",
    "    results_sorted = sorted(results, key=lambda x: x['final_test_acc'], reverse=True)\n",
    "    return results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Running iteration 1/20 with parameters: {'learning_rate': 0.01, 'hidden_size': 256, 'batch_size': 128, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8837, Train Acc: 59.15%, Test Loss: 0.8558, Test Acc: 60.65%\n",
      "Epoch 2/30, Train Loss: 0.8286, Train Acc: 62.21%, Test Loss: 0.8451, Test Acc: 61.55%\n",
      "Epoch 3/30, Train Loss: 0.8051, Train Acc: 63.32%, Test Loss: 0.8169, Test Acc: 63.70%\n",
      "Epoch 4/30, Train Loss: 0.7812, Train Acc: 65.12%, Test Loss: 0.8076, Test Acc: 64.40%\n",
      "Epoch 5/30, Train Loss: 0.7607, Train Acc: 66.35%, Test Loss: 0.8387, Test Acc: 62.00%\n",
      "Epoch 6/30, Train Loss: 0.7439, Train Acc: 67.23%, Test Loss: 0.7982, Test Acc: 64.95%\n",
      "Epoch 7/30, Train Loss: 0.7216, Train Acc: 68.95%, Test Loss: 0.8417, Test Acc: 61.75%\n",
      "Epoch 8/30, Train Loss: 0.7051, Train Acc: 69.59%, Test Loss: 0.8135, Test Acc: 63.60%\n",
      "Epoch 9/30, Train Loss: 0.6858, Train Acc: 70.34%, Test Loss: 0.8120, Test Acc: 63.90%\n",
      "Epoch 10/30, Train Loss: 0.6666, Train Acc: 71.43%, Test Loss: 0.8078, Test Acc: 63.65%\n",
      "Epoch 11/30, Train Loss: 0.6471, Train Acc: 72.34%, Test Loss: 0.9531, Test Acc: 59.80%\n",
      "Epoch 12/30, Train Loss: 0.6363, Train Acc: 72.81%, Test Loss: 0.8531, Test Acc: 63.05%\n",
      "Epoch 13/30, Train Loss: 0.6135, Train Acc: 73.95%, Test Loss: 0.8092, Test Acc: 65.40%\n",
      "Epoch 14/30, Train Loss: 0.6047, Train Acc: 75.05%, Test Loss: 0.8132, Test Acc: 63.60%\n",
      "Epoch 15/30, Train Loss: 0.5753, Train Acc: 76.23%, Test Loss: 1.0466, Test Acc: 57.55%\n",
      "Epoch 16/30, Train Loss: 0.5726, Train Acc: 76.18%, Test Loss: 0.8497, Test Acc: 63.90%\n",
      "Epoch 17/30, Train Loss: 0.5509, Train Acc: 77.12%, Test Loss: 0.8240, Test Acc: 62.85%\n",
      "Epoch 18/30, Train Loss: 0.5408, Train Acc: 77.69%, Test Loss: 0.7681, Test Acc: 65.80%\n",
      "Epoch 19/30, Train Loss: 0.5142, Train Acc: 79.39%, Test Loss: 0.8255, Test Acc: 64.10%\n",
      "Epoch 20/30, Train Loss: 0.5215, Train Acc: 78.61%, Test Loss: 0.8688, Test Acc: 64.35%\n",
      "Epoch 21/30, Train Loss: 0.4943, Train Acc: 80.30%, Test Loss: 0.8296, Test Acc: 63.40%\n",
      "Epoch 22/30, Train Loss: 0.4854, Train Acc: 80.78%, Test Loss: 1.1080, Test Acc: 59.20%\n",
      "Epoch 23/30, Train Loss: 0.4843, Train Acc: 80.76%, Test Loss: 0.8283, Test Acc: 64.60%\n",
      "Epoch 24/30, Train Loss: 0.4705, Train Acc: 80.92%, Test Loss: 0.8403, Test Acc: 62.80%\n",
      "Epoch 25/30, Train Loss: 0.4711, Train Acc: 81.44%, Test Loss: 0.8945, Test Acc: 61.30%\n",
      "Epoch 26/30, Train Loss: 0.4883, Train Acc: 80.34%, Test Loss: 1.0796, Test Acc: 59.40%\n",
      "Epoch 27/30, Train Loss: 0.4551, Train Acc: 81.89%, Test Loss: 1.0249, Test Acc: 61.65%\n",
      "Epoch 28/30, Train Loss: 0.4352, Train Acc: 83.13%, Test Loss: 1.0664, Test Acc: 58.75%\n",
      "Epoch 29/30, Train Loss: 0.4357, Train Acc: 82.81%, Test Loss: 0.9818, Test Acc: 61.75%\n",
      "Epoch 30/30, Train Loss: 0.4527, Train Acc: 82.33%, Test Loss: 0.9383, Test Acc: 63.60%\n",
      "\n",
      "Final Training Accuracy: 77.61%\n",
      "Final Test Accuracy: 63.60%\n",
      "\n",
      "Running iteration 2/20 with parameters: {'learning_rate': 0.01, 'hidden_size': 512, 'batch_size': 64, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8733, Train Acc: 60.11%, Test Loss: 0.8501, Test Acc: 60.50%\n",
      "Epoch 2/30, Train Loss: 0.8036, Train Acc: 63.49%, Test Loss: 0.8470, Test Acc: 62.60%\n",
      "Epoch 3/30, Train Loss: 0.7677, Train Acc: 65.90%, Test Loss: 0.8150, Test Acc: 63.90%\n",
      "Epoch 4/30, Train Loss: 0.7399, Train Acc: 67.39%, Test Loss: 0.8063, Test Acc: 63.60%\n",
      "Epoch 5/30, Train Loss: 0.7015, Train Acc: 69.72%, Test Loss: 0.8036, Test Acc: 63.80%\n",
      "Epoch 6/30, Train Loss: 0.6766, Train Acc: 70.98%, Test Loss: 0.8075, Test Acc: 64.30%\n",
      "Epoch 7/30, Train Loss: 0.6458, Train Acc: 72.53%, Test Loss: 0.8328, Test Acc: 62.50%\n",
      "Epoch 8/30, Train Loss: 0.6282, Train Acc: 73.05%, Test Loss: 0.9022, Test Acc: 59.35%\n",
      "Epoch 9/30, Train Loss: 0.5976, Train Acc: 74.51%, Test Loss: 0.8743, Test Acc: 63.95%\n",
      "Epoch 10/30, Train Loss: 0.5682, Train Acc: 76.28%, Test Loss: 0.8463, Test Acc: 64.10%\n",
      "Epoch 11/30, Train Loss: 0.5542, Train Acc: 76.87%, Test Loss: 0.8426, Test Acc: 64.10%\n",
      "Epoch 12/30, Train Loss: 0.5324, Train Acc: 78.34%, Test Loss: 0.9317, Test Acc: 61.30%\n",
      "Epoch 13/30, Train Loss: 0.5062, Train Acc: 79.50%, Test Loss: 1.0098, Test Acc: 61.95%\n",
      "Epoch 14/30, Train Loss: 0.4900, Train Acc: 80.25%, Test Loss: 0.8799, Test Acc: 62.25%\n",
      "Epoch 15/30, Train Loss: 0.4726, Train Acc: 81.28%, Test Loss: 0.9687, Test Acc: 60.05%\n",
      "Epoch 16/30, Train Loss: 0.4662, Train Acc: 81.40%, Test Loss: 0.8577, Test Acc: 64.35%\n",
      "Epoch 17/30, Train Loss: 0.4364, Train Acc: 82.70%, Test Loss: 0.8302, Test Acc: 63.65%\n",
      "Epoch 18/30, Train Loss: 0.4360, Train Acc: 82.69%, Test Loss: 0.8809, Test Acc: 63.20%\n",
      "Epoch 19/30, Train Loss: 0.4226, Train Acc: 83.51%, Test Loss: 1.0144, Test Acc: 62.35%\n",
      "Epoch 20/30, Train Loss: 0.4194, Train Acc: 83.67%, Test Loss: 0.9123, Test Acc: 63.85%\n",
      "Epoch 21/30, Train Loss: 0.3863, Train Acc: 85.20%, Test Loss: 1.0653, Test Acc: 61.80%\n",
      "Epoch 22/30, Train Loss: 0.3846, Train Acc: 85.24%, Test Loss: 0.9035, Test Acc: 63.60%\n",
      "Epoch 23/30, Train Loss: 0.3717, Train Acc: 85.57%, Test Loss: 0.8935, Test Acc: 64.10%\n",
      "Epoch 24/30, Train Loss: 0.3612, Train Acc: 86.09%, Test Loss: 1.0881, Test Acc: 62.75%\n",
      "Epoch 25/30, Train Loss: 0.3443, Train Acc: 86.41%, Test Loss: 0.8611, Test Acc: 64.40%\n",
      "Epoch 26/30, Train Loss: 0.3394, Train Acc: 87.04%, Test Loss: 1.0285, Test Acc: 59.55%\n",
      "Epoch 27/30, Train Loss: 0.3295, Train Acc: 87.47%, Test Loss: 1.0135, Test Acc: 61.45%\n",
      "Epoch 28/30, Train Loss: 0.3196, Train Acc: 87.97%, Test Loss: 0.9356, Test Acc: 63.55%\n",
      "Epoch 29/30, Train Loss: 0.3005, Train Acc: 88.65%, Test Loss: 1.1886, Test Acc: 58.35%\n",
      "Epoch 30/30, Train Loss: 0.2933, Train Acc: 89.06%, Test Loss: 1.0287, Test Acc: 60.70%\n",
      "\n",
      "Final Training Accuracy: 85.30%\n",
      "Final Test Accuracy: 60.70%\n",
      "\n",
      "Running iteration 3/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8596, Train Acc: 60.66%, Test Loss: 0.8259, Test Acc: 63.35%\n",
      "Epoch 2/30, Train Loss: 0.7847, Train Acc: 64.97%, Test Loss: 0.8050, Test Acc: 63.45%\n",
      "Epoch 3/30, Train Loss: 0.7338, Train Acc: 67.89%, Test Loss: 0.7953, Test Acc: 64.45%\n",
      "Epoch 4/30, Train Loss: 0.6914, Train Acc: 69.77%, Test Loss: 0.8024, Test Acc: 64.45%\n",
      "Epoch 5/30, Train Loss: 0.6675, Train Acc: 71.32%, Test Loss: 0.7807, Test Acc: 65.50%\n",
      "Epoch 6/30, Train Loss: 0.6441, Train Acc: 72.60%, Test Loss: 0.7820, Test Acc: 64.90%\n",
      "Epoch 7/30, Train Loss: 0.6223, Train Acc: 73.74%, Test Loss: 0.7896, Test Acc: 64.40%\n",
      "Epoch 8/30, Train Loss: 0.5821, Train Acc: 75.92%, Test Loss: 0.7638, Test Acc: 66.10%\n",
      "Epoch 9/30, Train Loss: 0.5543, Train Acc: 77.14%, Test Loss: 0.7692, Test Acc: 65.75%\n",
      "Epoch 10/30, Train Loss: 0.5332, Train Acc: 78.19%, Test Loss: 0.7880, Test Acc: 65.90%\n",
      "Epoch 11/30, Train Loss: 0.5134, Train Acc: 79.48%, Test Loss: 0.8106, Test Acc: 64.15%\n",
      "Epoch 12/30, Train Loss: 0.4910, Train Acc: 80.57%, Test Loss: 0.7784, Test Acc: 66.20%\n",
      "Epoch 13/30, Train Loss: 0.4701, Train Acc: 81.43%, Test Loss: 0.7812, Test Acc: 64.85%\n",
      "Epoch 14/30, Train Loss: 0.4456, Train Acc: 82.55%, Test Loss: 0.7859, Test Acc: 65.25%\n",
      "Epoch 15/30, Train Loss: 0.4330, Train Acc: 83.62%, Test Loss: 0.7781, Test Acc: 65.30%\n",
      "Epoch 16/30, Train Loss: 0.4160, Train Acc: 84.16%, Test Loss: 0.7901, Test Acc: 65.60%\n",
      "Epoch 17/30, Train Loss: 0.3904, Train Acc: 85.08%, Test Loss: 0.7770, Test Acc: 65.30%\n",
      "Epoch 18/30, Train Loss: 0.3690, Train Acc: 86.19%, Test Loss: 0.8037, Test Acc: 65.15%\n",
      "Epoch 19/30, Train Loss: 0.3444, Train Acc: 87.36%, Test Loss: 0.8178, Test Acc: 63.85%\n",
      "Epoch 20/30, Train Loss: 0.3305, Train Acc: 88.17%, Test Loss: 0.7975, Test Acc: 65.30%\n",
      "Epoch 21/30, Train Loss: 0.3103, Train Acc: 88.88%, Test Loss: 0.7854, Test Acc: 64.65%\n",
      "Epoch 22/30, Train Loss: 0.2974, Train Acc: 89.43%, Test Loss: 0.8100, Test Acc: 64.45%\n",
      "Epoch 23/30, Train Loss: 0.2869, Train Acc: 90.08%, Test Loss: 0.7907, Test Acc: 64.45%\n",
      "Epoch 24/30, Train Loss: 0.2635, Train Acc: 91.23%, Test Loss: 0.8093, Test Acc: 64.40%\n",
      "Epoch 25/30, Train Loss: 0.2536, Train Acc: 91.24%, Test Loss: 0.8126, Test Acc: 64.45%\n",
      "Epoch 26/30, Train Loss: 0.2412, Train Acc: 91.91%, Test Loss: 0.8043, Test Acc: 65.40%\n",
      "Epoch 27/30, Train Loss: 0.2207, Train Acc: 92.50%, Test Loss: 0.8067, Test Acc: 64.20%\n",
      "Epoch 28/30, Train Loss: 0.2085, Train Acc: 93.26%, Test Loss: 0.8014, Test Acc: 64.70%\n",
      "Epoch 29/30, Train Loss: 0.2005, Train Acc: 94.00%, Test Loss: 0.8302, Test Acc: 64.05%\n",
      "Epoch 30/30, Train Loss: 0.1865, Train Acc: 93.76%, Test Loss: 0.8041, Test Acc: 64.65%\n",
      "\n",
      "Final Training Accuracy: 95.50%\n",
      "Final Test Accuracy: 64.65%\n",
      "\n",
      "Running iteration 4/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 32, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8702, Train Acc: 60.56%, Test Loss: 0.8508, Test Acc: 62.45%\n",
      "Epoch 2/30, Train Loss: 0.7830, Train Acc: 65.42%, Test Loss: 0.7920, Test Acc: 65.50%\n",
      "Epoch 3/30, Train Loss: 0.7298, Train Acc: 68.52%, Test Loss: 0.8027, Test Acc: 63.40%\n",
      "Epoch 4/30, Train Loss: 0.6879, Train Acc: 70.21%, Test Loss: 0.8204, Test Acc: 64.10%\n",
      "Epoch 5/30, Train Loss: 0.6523, Train Acc: 71.85%, Test Loss: 0.8076, Test Acc: 65.65%\n",
      "Epoch 6/30, Train Loss: 0.6291, Train Acc: 73.27%, Test Loss: 0.8053, Test Acc: 64.20%\n",
      "Epoch 7/30, Train Loss: 0.5950, Train Acc: 74.80%, Test Loss: 0.7952, Test Acc: 65.55%\n",
      "Epoch 8/30, Train Loss: 0.5633, Train Acc: 76.55%, Test Loss: 0.7821, Test Acc: 65.40%\n",
      "Epoch 9/30, Train Loss: 0.5318, Train Acc: 78.36%, Test Loss: 0.7811, Test Acc: 65.35%\n",
      "Epoch 10/30, Train Loss: 0.5015, Train Acc: 79.25%, Test Loss: 0.8055, Test Acc: 64.15%\n",
      "Epoch 11/30, Train Loss: 0.4730, Train Acc: 81.23%, Test Loss: 0.8246, Test Acc: 62.60%\n",
      "Epoch 12/30, Train Loss: 0.4489, Train Acc: 82.34%, Test Loss: 0.8006, Test Acc: 64.60%\n",
      "Epoch 13/30, Train Loss: 0.4187, Train Acc: 83.48%, Test Loss: 0.8862, Test Acc: 62.10%\n",
      "Epoch 14/30, Train Loss: 0.3981, Train Acc: 84.50%, Test Loss: 0.8218, Test Acc: 64.70%\n",
      "Epoch 15/30, Train Loss: 0.3635, Train Acc: 85.95%, Test Loss: 0.8448, Test Acc: 62.90%\n",
      "Epoch 16/30, Train Loss: 0.3271, Train Acc: 87.69%, Test Loss: 0.8341, Test Acc: 64.75%\n",
      "Epoch 17/30, Train Loss: 0.3133, Train Acc: 88.19%, Test Loss: 0.8592, Test Acc: 64.40%\n",
      "Epoch 18/30, Train Loss: 0.2917, Train Acc: 89.09%, Test Loss: 0.8518, Test Acc: 63.25%\n",
      "Epoch 19/30, Train Loss: 0.2713, Train Acc: 89.99%, Test Loss: 0.8408, Test Acc: 63.80%\n",
      "Epoch 20/30, Train Loss: 0.2553, Train Acc: 90.70%, Test Loss: 0.8508, Test Acc: 64.30%\n",
      "Epoch 21/30, Train Loss: 0.2370, Train Acc: 91.68%, Test Loss: 0.8467, Test Acc: 63.90%\n",
      "Epoch 22/30, Train Loss: 0.2182, Train Acc: 92.27%, Test Loss: 0.8740, Test Acc: 62.85%\n",
      "Epoch 23/30, Train Loss: 0.2057, Train Acc: 92.67%, Test Loss: 0.9002, Test Acc: 63.60%\n",
      "Epoch 24/30, Train Loss: 0.1801, Train Acc: 93.73%, Test Loss: 0.8753, Test Acc: 64.05%\n",
      "Epoch 25/30, Train Loss: 0.1691, Train Acc: 94.29%, Test Loss: 0.9187, Test Acc: 62.40%\n",
      "Epoch 26/30, Train Loss: 0.1575, Train Acc: 94.94%, Test Loss: 0.8769, Test Acc: 62.95%\n",
      "Epoch 27/30, Train Loss: 0.1477, Train Acc: 95.28%, Test Loss: 0.8907, Test Acc: 63.60%\n",
      "Epoch 28/30, Train Loss: 0.1375, Train Acc: 95.63%, Test Loss: 0.8973, Test Acc: 64.50%\n",
      "Epoch 29/30, Train Loss: 0.1240, Train Acc: 96.10%, Test Loss: 0.9069, Test Acc: 63.90%\n",
      "Epoch 30/30, Train Loss: 0.1167, Train Acc: 96.27%, Test Loss: 0.9117, Test Acc: 64.30%\n",
      "\n",
      "Final Training Accuracy: 97.62%\n",
      "Final Test Accuracy: 64.30%\n",
      "\n",
      "Running iteration 5/20 with parameters: {'learning_rate': 0.01, 'hidden_size': 128, 'batch_size': 32, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8654, Train Acc: 59.50%, Test Loss: 0.8435, Test Acc: 62.70%\n",
      "Epoch 2/30, Train Loss: 0.8013, Train Acc: 64.17%, Test Loss: 0.8225, Test Acc: 63.75%\n",
      "Epoch 3/30, Train Loss: 0.7681, Train Acc: 65.81%, Test Loss: 0.8402, Test Acc: 61.85%\n",
      "Epoch 4/30, Train Loss: 0.7351, Train Acc: 68.08%, Test Loss: 0.8183, Test Acc: 64.10%\n",
      "Epoch 5/30, Train Loss: 0.7076, Train Acc: 68.94%, Test Loss: 0.8029, Test Acc: 64.00%\n",
      "Epoch 6/30, Train Loss: 0.6727, Train Acc: 70.68%, Test Loss: 0.8012, Test Acc: 64.10%\n",
      "Epoch 7/30, Train Loss: 0.6564, Train Acc: 71.53%, Test Loss: 0.8052, Test Acc: 64.05%\n",
      "Epoch 8/30, Train Loss: 0.6274, Train Acc: 73.18%, Test Loss: 0.9599, Test Acc: 59.60%\n",
      "Epoch 9/30, Train Loss: 0.6059, Train Acc: 74.18%, Test Loss: 0.8539, Test Acc: 61.05%\n",
      "Epoch 10/30, Train Loss: 0.5742, Train Acc: 76.50%, Test Loss: 0.8616, Test Acc: 63.45%\n",
      "Epoch 11/30, Train Loss: 0.5611, Train Acc: 76.83%, Test Loss: 0.8330, Test Acc: 63.95%\n",
      "Epoch 12/30, Train Loss: 0.5389, Train Acc: 77.65%, Test Loss: 0.9052, Test Acc: 60.45%\n",
      "Epoch 13/30, Train Loss: 0.5144, Train Acc: 78.67%, Test Loss: 0.8471, Test Acc: 62.90%\n",
      "Epoch 14/30, Train Loss: 0.4948, Train Acc: 79.99%, Test Loss: 0.8403, Test Acc: 63.60%\n",
      "Epoch 15/30, Train Loss: 0.4789, Train Acc: 80.45%, Test Loss: 0.8296, Test Acc: 65.70%\n",
      "Epoch 16/30, Train Loss: 0.4581, Train Acc: 81.67%, Test Loss: 0.9835, Test Acc: 59.75%\n",
      "Epoch 17/30, Train Loss: 0.4448, Train Acc: 82.23%, Test Loss: 0.9082, Test Acc: 63.15%\n",
      "Epoch 18/30, Train Loss: 0.4244, Train Acc: 82.95%, Test Loss: 0.9759, Test Acc: 61.15%\n",
      "Epoch 19/30, Train Loss: 0.4136, Train Acc: 83.40%, Test Loss: 0.9316, Test Acc: 63.15%\n",
      "Epoch 20/30, Train Loss: 0.3903, Train Acc: 84.45%, Test Loss: 0.8865, Test Acc: 64.25%\n",
      "Epoch 21/30, Train Loss: 0.3748, Train Acc: 85.47%, Test Loss: 0.8906, Test Acc: 64.65%\n",
      "Epoch 22/30, Train Loss: 0.3646, Train Acc: 85.51%, Test Loss: 0.9281, Test Acc: 62.85%\n",
      "Epoch 23/30, Train Loss: 0.3387, Train Acc: 87.11%, Test Loss: 0.9127, Test Acc: 62.40%\n",
      "Epoch 24/30, Train Loss: 0.3445, Train Acc: 86.51%, Test Loss: 1.1344, Test Acc: 63.80%\n",
      "Epoch 25/30, Train Loss: 0.3218, Train Acc: 87.45%, Test Loss: 0.9494, Test Acc: 63.05%\n",
      "Epoch 26/30, Train Loss: 0.3129, Train Acc: 88.07%, Test Loss: 1.2377, Test Acc: 58.90%\n",
      "Epoch 27/30, Train Loss: 0.2937, Train Acc: 88.72%, Test Loss: 1.3642, Test Acc: 56.60%\n",
      "Epoch 28/30, Train Loss: 0.2941, Train Acc: 88.79%, Test Loss: 1.2702, Test Acc: 58.25%\n",
      "Epoch 29/30, Train Loss: 0.2788, Train Acc: 89.40%, Test Loss: 1.0835, Test Acc: 60.85%\n",
      "Epoch 30/30, Train Loss: 0.2720, Train Acc: 89.47%, Test Loss: 1.0788, Test Acc: 61.85%\n",
      "\n",
      "Final Training Accuracy: 87.22%\n",
      "Final Test Accuracy: 61.85%\n",
      "\n",
      "Running iteration 6/20 with parameters: {'learning_rate': 0.001, 'hidden_size': 512, 'batch_size': 32, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.9735, Train Acc: 59.29%, Test Loss: 0.8449, Test Acc: 62.05%\n",
      "Epoch 2/30, Train Loss: 0.8462, Train Acc: 61.79%, Test Loss: 0.8477, Test Acc: 62.65%\n",
      "Epoch 3/30, Train Loss: 0.8308, Train Acc: 63.78%, Test Loss: 0.9512, Test Acc: 60.20%\n",
      "Epoch 4/30, Train Loss: 0.7990, Train Acc: 65.12%, Test Loss: 0.9092, Test Acc: 60.70%\n",
      "Epoch 5/30, Train Loss: 0.7732, Train Acc: 66.57%, Test Loss: 0.9356, Test Acc: 60.80%\n",
      "Epoch 6/30, Train Loss: 0.7657, Train Acc: 67.79%, Test Loss: 0.8557, Test Acc: 62.05%\n",
      "Epoch 7/30, Train Loss: 0.7224, Train Acc: 69.42%, Test Loss: 0.8742, Test Acc: 62.60%\n",
      "Epoch 8/30, Train Loss: 0.6924, Train Acc: 70.89%, Test Loss: 0.8281, Test Acc: 63.55%\n",
      "Epoch 9/30, Train Loss: 0.6590, Train Acc: 72.80%, Test Loss: 0.8680, Test Acc: 64.05%\n",
      "Epoch 10/30, Train Loss: 0.6463, Train Acc: 73.47%, Test Loss: 1.0852, Test Acc: 56.65%\n",
      "Epoch 11/30, Train Loss: 0.6215, Train Acc: 74.34%, Test Loss: 0.8789, Test Acc: 62.30%\n",
      "Epoch 12/30, Train Loss: 0.5799, Train Acc: 76.38%, Test Loss: 0.9895, Test Acc: 59.50%\n",
      "Epoch 13/30, Train Loss: 0.5772, Train Acc: 77.07%, Test Loss: 0.9418, Test Acc: 64.75%\n",
      "Epoch 14/30, Train Loss: 0.5369, Train Acc: 78.74%, Test Loss: 0.8970, Test Acc: 65.30%\n",
      "Epoch 15/30, Train Loss: 0.5068, Train Acc: 79.80%, Test Loss: 1.0406, Test Acc: 60.70%\n",
      "Epoch 16/30, Train Loss: 0.4954, Train Acc: 80.72%, Test Loss: 0.9905, Test Acc: 61.90%\n",
      "Epoch 17/30, Train Loss: 0.4695, Train Acc: 81.74%, Test Loss: 1.0010, Test Acc: 62.65%\n",
      "Epoch 18/30, Train Loss: 0.4500, Train Acc: 82.35%, Test Loss: 1.0342, Test Acc: 63.00%\n",
      "Epoch 19/30, Train Loss: 0.4175, Train Acc: 83.50%, Test Loss: 0.9936, Test Acc: 62.70%\n",
      "Epoch 20/30, Train Loss: 0.4053, Train Acc: 84.27%, Test Loss: 1.0231, Test Acc: 63.75%\n",
      "Epoch 21/30, Train Loss: 0.3596, Train Acc: 85.72%, Test Loss: 1.0774, Test Acc: 63.75%\n",
      "Epoch 22/30, Train Loss: 0.3783, Train Acc: 85.73%, Test Loss: 1.2148, Test Acc: 61.20%\n",
      "Epoch 23/30, Train Loss: 0.3498, Train Acc: 86.74%, Test Loss: 1.1325, Test Acc: 60.80%\n",
      "Epoch 24/30, Train Loss: 0.3275, Train Acc: 87.45%, Test Loss: 1.2148, Test Acc: 61.60%\n",
      "Epoch 25/30, Train Loss: 0.3020, Train Acc: 88.47%, Test Loss: 1.1173, Test Acc: 64.80%\n",
      "Epoch 26/30, Train Loss: 0.3008, Train Acc: 88.79%, Test Loss: 1.2130, Test Acc: 62.30%\n",
      "Epoch 27/30, Train Loss: 0.2873, Train Acc: 89.22%, Test Loss: 1.3593, Test Acc: 60.20%\n",
      "Epoch 28/30, Train Loss: 0.2545, Train Acc: 90.19%, Test Loss: 1.2886, Test Acc: 60.75%\n",
      "Epoch 29/30, Train Loss: 0.2626, Train Acc: 90.52%, Test Loss: 1.2887, Test Acc: 62.25%\n",
      "Epoch 30/30, Train Loss: 0.2324, Train Acc: 91.40%, Test Loss: 1.3929, Test Acc: 61.50%\n",
      "\n",
      "Final Training Accuracy: 90.17%\n",
      "Final Test Accuracy: 61.50%\n",
      "\n",
      "Running iteration 7/20 with parameters: {'learning_rate': 0.01, 'hidden_size': 256, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 1.7864, Train Acc: 55.80%, Test Loss: 1.0625, Test Acc: 53.65%\n",
      "Epoch 2/30, Train Loss: 0.9911, Train Acc: 58.36%, Test Loss: 0.9956, Test Acc: 60.85%\n",
      "Epoch 3/30, Train Loss: 0.9968, Train Acc: 60.51%, Test Loss: 1.0100, Test Acc: 59.30%\n",
      "Epoch 4/30, Train Loss: 1.0318, Train Acc: 60.73%, Test Loss: 1.0339, Test Acc: 61.45%\n",
      "Epoch 5/30, Train Loss: 1.0391, Train Acc: 62.10%, Test Loss: 1.4255, Test Acc: 57.85%\n",
      "Epoch 6/30, Train Loss: 1.1422, Train Acc: 61.39%, Test Loss: 1.4438, Test Acc: 56.05%\n",
      "Epoch 7/30, Train Loss: 1.2176, Train Acc: 61.37%, Test Loss: 2.1778, Test Acc: 53.35%\n",
      "Epoch 8/30, Train Loss: 1.7268, Train Acc: 61.39%, Test Loss: 1.8359, Test Acc: 56.25%\n",
      "Epoch 9/30, Train Loss: 1.0881, Train Acc: 64.41%, Test Loss: 1.0488, Test Acc: 61.80%\n",
      "Epoch 10/30, Train Loss: 0.9775, Train Acc: 65.97%, Test Loss: 1.1698, Test Acc: 59.90%\n",
      "Epoch 11/30, Train Loss: 1.0630, Train Acc: 65.56%, Test Loss: 1.0381, Test Acc: 62.10%\n",
      "Epoch 12/30, Train Loss: 1.0491, Train Acc: 65.90%, Test Loss: 1.5345, Test Acc: 59.65%\n",
      "Epoch 13/30, Train Loss: 0.9516, Train Acc: 68.30%, Test Loss: 1.1653, Test Acc: 59.30%\n",
      "Epoch 14/30, Train Loss: 1.1912, Train Acc: 67.03%, Test Loss: 1.2042, Test Acc: 61.45%\n",
      "Epoch 15/30, Train Loss: 0.9771, Train Acc: 68.39%, Test Loss: 1.1451, Test Acc: 59.55%\n",
      "Epoch 16/30, Train Loss: 0.9345, Train Acc: 70.82%, Test Loss: 1.1522, Test Acc: 61.20%\n",
      "Epoch 17/30, Train Loss: 0.9416, Train Acc: 70.73%, Test Loss: 1.1562, Test Acc: 61.00%\n",
      "Epoch 18/30, Train Loss: 0.9303, Train Acc: 71.13%, Test Loss: 1.7849, Test Acc: 59.75%\n",
      "Epoch 19/30, Train Loss: 1.0657, Train Acc: 70.35%, Test Loss: 1.5530, Test Acc: 58.25%\n",
      "Epoch 20/30, Train Loss: 0.8327, Train Acc: 73.37%, Test Loss: 1.2030, Test Acc: 60.45%\n",
      "Epoch 21/30, Train Loss: 0.7198, Train Acc: 75.43%, Test Loss: 1.9185, Test Acc: 55.55%\n",
      "Epoch 22/30, Train Loss: 1.2041, Train Acc: 70.66%, Test Loss: 1.8138, Test Acc: 56.00%\n",
      "Epoch 23/30, Train Loss: 0.8157, Train Acc: 74.23%, Test Loss: 1.1616, Test Acc: 61.35%\n",
      "Epoch 24/30, Train Loss: 0.7440, Train Acc: 76.03%, Test Loss: 1.6459, Test Acc: 57.85%\n",
      "Epoch 25/30, Train Loss: 0.7982, Train Acc: 76.06%, Test Loss: 1.5914, Test Acc: 60.80%\n",
      "Epoch 26/30, Train Loss: 0.9599, Train Acc: 75.01%, Test Loss: 1.4959, Test Acc: 62.25%\n",
      "Epoch 27/30, Train Loss: 0.8883, Train Acc: 75.85%, Test Loss: 1.5266, Test Acc: 60.40%\n",
      "Epoch 28/30, Train Loss: 0.7379, Train Acc: 77.61%, Test Loss: 1.3664, Test Acc: 60.70%\n",
      "Epoch 29/30, Train Loss: 0.6809, Train Acc: 79.29%, Test Loss: 1.5712, Test Acc: 60.15%\n",
      "Epoch 30/30, Train Loss: 0.7107, Train Acc: 78.64%, Test Loss: 2.0794, Test Acc: 60.75%\n",
      "\n",
      "Final Training Accuracy: 73.96%\n",
      "Final Test Accuracy: 60.75%\n",
      "\n",
      "Running iteration 8/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 1.0029, Train Acc: 49.85%, Test Loss: 0.9921, Test Acc: 50.25%\n",
      "Epoch 2/30, Train Loss: 0.9935, Train Acc: 51.65%, Test Loss: 0.9819, Test Acc: 51.65%\n",
      "Epoch 3/30, Train Loss: 0.9839, Train Acc: 53.17%, Test Loss: 0.9718, Test Acc: 53.95%\n",
      "Epoch 4/30, Train Loss: 0.9744, Train Acc: 54.40%, Test Loss: 0.9616, Test Acc: 55.25%\n",
      "Epoch 5/30, Train Loss: 0.9648, Train Acc: 55.29%, Test Loss: 0.9514, Test Acc: 56.00%\n",
      "Epoch 6/30, Train Loss: 0.9554, Train Acc: 56.02%, Test Loss: 0.9413, Test Acc: 56.45%\n",
      "Epoch 7/30, Train Loss: 0.9461, Train Acc: 56.91%, Test Loss: 0.9318, Test Acc: 57.45%\n",
      "Epoch 8/30, Train Loss: 0.9374, Train Acc: 57.38%, Test Loss: 0.9231, Test Acc: 58.10%\n",
      "Epoch 9/30, Train Loss: 0.9294, Train Acc: 57.82%, Test Loss: 0.9150, Test Acc: 58.10%\n",
      "Epoch 10/30, Train Loss: 0.9221, Train Acc: 58.10%, Test Loss: 0.9081, Test Acc: 58.15%\n",
      "Epoch 11/30, Train Loss: 0.9160, Train Acc: 58.07%, Test Loss: 0.9020, Test Acc: 57.85%\n",
      "Epoch 12/30, Train Loss: 0.9104, Train Acc: 58.23%, Test Loss: 0.8968, Test Acc: 57.90%\n",
      "Epoch 13/30, Train Loss: 0.9057, Train Acc: 58.37%, Test Loss: 0.8923, Test Acc: 58.20%\n",
      "Epoch 14/30, Train Loss: 0.9017, Train Acc: 58.52%, Test Loss: 0.8885, Test Acc: 58.00%\n",
      "Epoch 15/30, Train Loss: 0.8983, Train Acc: 58.54%, Test Loss: 0.8854, Test Acc: 58.25%\n",
      "Epoch 16/30, Train Loss: 0.8953, Train Acc: 58.65%, Test Loss: 0.8827, Test Acc: 58.60%\n",
      "Epoch 17/30, Train Loss: 0.8928, Train Acc: 58.66%, Test Loss: 0.8803, Test Acc: 58.85%\n",
      "Epoch 18/30, Train Loss: 0.8905, Train Acc: 58.83%, Test Loss: 0.8784, Test Acc: 59.10%\n",
      "Epoch 19/30, Train Loss: 0.8885, Train Acc: 58.92%, Test Loss: 0.8767, Test Acc: 59.15%\n",
      "Epoch 20/30, Train Loss: 0.8867, Train Acc: 58.94%, Test Loss: 0.8749, Test Acc: 59.50%\n",
      "Epoch 21/30, Train Loss: 0.8849, Train Acc: 59.00%, Test Loss: 0.8734, Test Acc: 59.35%\n",
      "Epoch 22/30, Train Loss: 0.8833, Train Acc: 59.08%, Test Loss: 0.8719, Test Acc: 59.70%\n",
      "Epoch 23/30, Train Loss: 0.8818, Train Acc: 59.29%, Test Loss: 0.8708, Test Acc: 60.05%\n",
      "Epoch 24/30, Train Loss: 0.8804, Train Acc: 59.36%, Test Loss: 0.8697, Test Acc: 60.10%\n",
      "Epoch 25/30, Train Loss: 0.8791, Train Acc: 59.50%, Test Loss: 0.8686, Test Acc: 60.05%\n",
      "Epoch 26/30, Train Loss: 0.8777, Train Acc: 59.49%, Test Loss: 0.8676, Test Acc: 60.15%\n",
      "Epoch 27/30, Train Loss: 0.8764, Train Acc: 59.61%, Test Loss: 0.8669, Test Acc: 60.00%\n",
      "Epoch 28/30, Train Loss: 0.8751, Train Acc: 59.71%, Test Loss: 0.8660, Test Acc: 59.90%\n",
      "Epoch 29/30, Train Loss: 0.8739, Train Acc: 59.79%, Test Loss: 0.8651, Test Acc: 59.95%\n",
      "Epoch 30/30, Train Loss: 0.8727, Train Acc: 59.82%, Test Loss: 0.8641, Test Acc: 60.10%\n",
      "\n",
      "Final Training Accuracy: 59.79%\n",
      "Final Test Accuracy: 60.10%\n",
      "\n",
      "Running iteration 9/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8713, Train Acc: 60.47%, Test Loss: 0.8311, Test Acc: 62.70%\n",
      "Epoch 2/30, Train Loss: 0.7898, Train Acc: 64.86%, Test Loss: 0.8092, Test Acc: 63.85%\n",
      "Epoch 3/30, Train Loss: 0.7413, Train Acc: 67.22%, Test Loss: 0.8111, Test Acc: 63.90%\n",
      "Epoch 4/30, Train Loss: 0.7139, Train Acc: 69.04%, Test Loss: 0.7875, Test Acc: 64.65%\n",
      "Epoch 5/30, Train Loss: 0.6779, Train Acc: 70.77%, Test Loss: 0.7878, Test Acc: 65.65%\n",
      "Epoch 6/30, Train Loss: 0.6422, Train Acc: 72.65%, Test Loss: 0.7776, Test Acc: 65.80%\n",
      "Epoch 7/30, Train Loss: 0.6220, Train Acc: 73.72%, Test Loss: 0.7803, Test Acc: 66.20%\n",
      "Epoch 8/30, Train Loss: 0.5950, Train Acc: 74.93%, Test Loss: 0.7951, Test Acc: 65.90%\n",
      "Epoch 9/30, Train Loss: 0.5650, Train Acc: 76.74%, Test Loss: 0.7815, Test Acc: 64.10%\n",
      "Epoch 10/30, Train Loss: 0.5461, Train Acc: 77.48%, Test Loss: 0.7850, Test Acc: 64.70%\n",
      "Epoch 11/30, Train Loss: 0.5270, Train Acc: 78.36%, Test Loss: 0.7965, Test Acc: 64.80%\n",
      "Epoch 12/30, Train Loss: 0.5121, Train Acc: 79.65%, Test Loss: 0.8227, Test Acc: 63.80%\n",
      "Epoch 13/30, Train Loss: 0.4872, Train Acc: 80.42%, Test Loss: 0.8087, Test Acc: 64.45%\n",
      "Epoch 14/30, Train Loss: 0.4613, Train Acc: 82.26%, Test Loss: 0.7956, Test Acc: 64.15%\n",
      "Epoch 15/30, Train Loss: 0.4334, Train Acc: 83.56%, Test Loss: 0.7909, Test Acc: 64.65%\n",
      "Epoch 16/30, Train Loss: 0.4162, Train Acc: 84.18%, Test Loss: 0.8312, Test Acc: 63.55%\n",
      "Epoch 17/30, Train Loss: 0.3996, Train Acc: 84.60%, Test Loss: 0.7819, Test Acc: 66.15%\n",
      "Epoch 18/30, Train Loss: 0.3702, Train Acc: 86.07%, Test Loss: 0.7969, Test Acc: 65.15%\n",
      "Epoch 19/30, Train Loss: 0.3582, Train Acc: 86.64%, Test Loss: 0.8053, Test Acc: 64.80%\n",
      "Epoch 20/30, Train Loss: 0.3383, Train Acc: 87.59%, Test Loss: 0.7960, Test Acc: 66.55%\n",
      "Epoch 21/30, Train Loss: 0.3144, Train Acc: 88.57%, Test Loss: 0.7953, Test Acc: 65.50%\n",
      "Epoch 22/30, Train Loss: 0.3073, Train Acc: 88.83%, Test Loss: 0.8205, Test Acc: 64.65%\n",
      "Epoch 23/30, Train Loss: 0.2858, Train Acc: 90.00%, Test Loss: 0.8080, Test Acc: 65.20%\n",
      "Epoch 24/30, Train Loss: 0.2787, Train Acc: 90.30%, Test Loss: 0.8375, Test Acc: 63.40%\n",
      "Epoch 25/30, Train Loss: 0.2600, Train Acc: 91.08%, Test Loss: 0.8215, Test Acc: 63.70%\n",
      "Epoch 26/30, Train Loss: 0.2469, Train Acc: 91.78%, Test Loss: 0.8076, Test Acc: 65.75%\n",
      "Epoch 27/30, Train Loss: 0.2320, Train Acc: 92.68%, Test Loss: 0.8093, Test Acc: 65.05%\n",
      "Epoch 28/30, Train Loss: 0.2355, Train Acc: 91.82%, Test Loss: 0.8299, Test Acc: 64.00%\n",
      "Epoch 29/30, Train Loss: 0.2037, Train Acc: 93.49%, Test Loss: 0.8160, Test Acc: 65.25%\n",
      "Epoch 30/30, Train Loss: 0.1993, Train Acc: 93.58%, Test Loss: 0.8355, Test Acc: 63.80%\n",
      "\n",
      "Final Training Accuracy: 94.48%\n",
      "Final Test Accuracy: 63.80%\n",
      "\n",
      "Running iteration 10/20 with parameters: {'learning_rate': 0.001, 'hidden_size': 512, 'batch_size': 64, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.9680, Train Acc: 58.95%, Test Loss: 0.8712, Test Acc: 61.10%\n",
      "Epoch 2/30, Train Loss: 0.8237, Train Acc: 63.03%, Test Loss: 0.8222, Test Acc: 63.55%\n",
      "Epoch 3/30, Train Loss: 0.7877, Train Acc: 65.19%, Test Loss: 0.8336, Test Acc: 63.70%\n",
      "Epoch 4/30, Train Loss: 0.7648, Train Acc: 66.46%, Test Loss: 0.8312, Test Acc: 62.95%\n",
      "Epoch 5/30, Train Loss: 0.7419, Train Acc: 68.05%, Test Loss: 0.8772, Test Acc: 60.95%\n",
      "Epoch 6/30, Train Loss: 0.7038, Train Acc: 69.63%, Test Loss: 0.8268, Test Acc: 64.55%\n",
      "Epoch 7/30, Train Loss: 0.6913, Train Acc: 70.92%, Test Loss: 0.8596, Test Acc: 63.10%\n",
      "Epoch 8/30, Train Loss: 0.6544, Train Acc: 72.09%, Test Loss: 0.8531, Test Acc: 62.95%\n",
      "Epoch 9/30, Train Loss: 0.6281, Train Acc: 73.50%, Test Loss: 0.8846, Test Acc: 64.15%\n",
      "Epoch 10/30, Train Loss: 0.5877, Train Acc: 75.12%, Test Loss: 0.8723, Test Acc: 63.20%\n",
      "Epoch 11/30, Train Loss: 0.5692, Train Acc: 76.46%, Test Loss: 0.8864, Test Acc: 62.90%\n",
      "Epoch 12/30, Train Loss: 0.5709, Train Acc: 77.15%, Test Loss: 0.8540, Test Acc: 64.75%\n",
      "Epoch 13/30, Train Loss: 0.5298, Train Acc: 78.60%, Test Loss: 0.9428, Test Acc: 62.15%\n",
      "Epoch 14/30, Train Loss: 0.4752, Train Acc: 80.66%, Test Loss: 0.8759, Test Acc: 64.20%\n",
      "Epoch 15/30, Train Loss: 0.4682, Train Acc: 80.86%, Test Loss: 0.9181, Test Acc: 64.85%\n",
      "Epoch 16/30, Train Loss: 0.4382, Train Acc: 82.58%, Test Loss: 0.9673, Test Acc: 62.60%\n",
      "Epoch 17/30, Train Loss: 0.4145, Train Acc: 82.99%, Test Loss: 0.9890, Test Acc: 62.15%\n",
      "Epoch 18/30, Train Loss: 0.3841, Train Acc: 84.81%, Test Loss: 1.0202, Test Acc: 61.05%\n",
      "Epoch 19/30, Train Loss: 0.3852, Train Acc: 84.98%, Test Loss: 1.0328, Test Acc: 62.35%\n",
      "Epoch 20/30, Train Loss: 0.3616, Train Acc: 85.71%, Test Loss: 1.0363, Test Acc: 61.45%\n",
      "Epoch 21/30, Train Loss: 0.3301, Train Acc: 86.95%, Test Loss: 1.0157, Test Acc: 62.30%\n",
      "Epoch 22/30, Train Loss: 0.3470, Train Acc: 86.66%, Test Loss: 1.0757, Test Acc: 62.45%\n",
      "Epoch 23/30, Train Loss: 0.3167, Train Acc: 87.70%, Test Loss: 1.1311, Test Acc: 61.75%\n",
      "Epoch 24/30, Train Loss: 0.2712, Train Acc: 89.43%, Test Loss: 1.1531, Test Acc: 61.65%\n",
      "Epoch 25/30, Train Loss: 0.2344, Train Acc: 91.00%, Test Loss: 1.1298, Test Acc: 61.35%\n",
      "Epoch 26/30, Train Loss: 0.2407, Train Acc: 90.70%, Test Loss: 1.1437, Test Acc: 61.95%\n",
      "Epoch 27/30, Train Loss: 0.2201, Train Acc: 91.50%, Test Loss: 1.1643, Test Acc: 61.95%\n",
      "Epoch 28/30, Train Loss: 0.2228, Train Acc: 91.13%, Test Loss: 1.1960, Test Acc: 61.30%\n",
      "Epoch 29/30, Train Loss: 0.1985, Train Acc: 92.49%, Test Loss: 1.2232, Test Acc: 61.55%\n",
      "Epoch 30/30, Train Loss: 0.1821, Train Acc: 93.03%, Test Loss: 1.1675, Test Acc: 64.00%\n",
      "\n",
      "Final Training Accuracy: 94.60%\n",
      "Final Test Accuracy: 64.00%\n",
      "\n",
      "Running iteration 11/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 256, 'batch_size': 64, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.9882, Train Acc: 50.47%, Test Loss: 0.9806, Test Acc: 52.10%\n",
      "Epoch 2/30, Train Loss: 0.9729, Train Acc: 51.64%, Test Loss: 0.9650, Test Acc: 53.45%\n",
      "Epoch 3/30, Train Loss: 0.9591, Train Acc: 52.94%, Test Loss: 0.9507, Test Acc: 54.85%\n",
      "Epoch 4/30, Train Loss: 0.9470, Train Acc: 54.09%, Test Loss: 0.9389, Test Acc: 56.25%\n",
      "Epoch 5/30, Train Loss: 0.9370, Train Acc: 55.28%, Test Loss: 0.9290, Test Acc: 57.35%\n",
      "Epoch 6/30, Train Loss: 0.9287, Train Acc: 55.93%, Test Loss: 0.9203, Test Acc: 57.75%\n",
      "Epoch 7/30, Train Loss: 0.9214, Train Acc: 56.42%, Test Loss: 0.9125, Test Acc: 58.15%\n",
      "Epoch 8/30, Train Loss: 0.9149, Train Acc: 56.88%, Test Loss: 0.9055, Test Acc: 58.45%\n",
      "Epoch 9/30, Train Loss: 0.9090, Train Acc: 57.10%, Test Loss: 0.8993, Test Acc: 58.70%\n",
      "Epoch 10/30, Train Loss: 0.9036, Train Acc: 57.37%, Test Loss: 0.8941, Test Acc: 58.90%\n",
      "Epoch 11/30, Train Loss: 0.8988, Train Acc: 57.65%, Test Loss: 0.8896, Test Acc: 59.20%\n",
      "Epoch 12/30, Train Loss: 0.8946, Train Acc: 58.01%, Test Loss: 0.8859, Test Acc: 59.40%\n",
      "Epoch 13/30, Train Loss: 0.8907, Train Acc: 58.30%, Test Loss: 0.8825, Test Acc: 60.05%\n",
      "Epoch 14/30, Train Loss: 0.8872, Train Acc: 58.40%, Test Loss: 0.8795, Test Acc: 60.10%\n",
      "Epoch 15/30, Train Loss: 0.8841, Train Acc: 58.60%, Test Loss: 0.8768, Test Acc: 60.40%\n",
      "Epoch 16/30, Train Loss: 0.8814, Train Acc: 58.80%, Test Loss: 0.8743, Test Acc: 60.75%\n",
      "Epoch 17/30, Train Loss: 0.8788, Train Acc: 58.96%, Test Loss: 0.8721, Test Acc: 60.70%\n",
      "Epoch 18/30, Train Loss: 0.8764, Train Acc: 59.08%, Test Loss: 0.8701, Test Acc: 61.00%\n",
      "Epoch 19/30, Train Loss: 0.8741, Train Acc: 59.19%, Test Loss: 0.8682, Test Acc: 60.95%\n",
      "Epoch 20/30, Train Loss: 0.8720, Train Acc: 59.36%, Test Loss: 0.8666, Test Acc: 61.00%\n",
      "Epoch 21/30, Train Loss: 0.8698, Train Acc: 59.51%, Test Loss: 0.8652, Test Acc: 61.15%\n",
      "Epoch 22/30, Train Loss: 0.8678, Train Acc: 59.54%, Test Loss: 0.8636, Test Acc: 61.15%\n",
      "Epoch 23/30, Train Loss: 0.8659, Train Acc: 59.66%, Test Loss: 0.8620, Test Acc: 61.15%\n",
      "Epoch 24/30, Train Loss: 0.8641, Train Acc: 59.79%, Test Loss: 0.8607, Test Acc: 61.20%\n",
      "Epoch 25/30, Train Loss: 0.8622, Train Acc: 59.83%, Test Loss: 0.8595, Test Acc: 61.15%\n",
      "Epoch 26/30, Train Loss: 0.8605, Train Acc: 59.84%, Test Loss: 0.8583, Test Acc: 61.05%\n",
      "Epoch 27/30, Train Loss: 0.8588, Train Acc: 59.90%, Test Loss: 0.8571, Test Acc: 61.25%\n",
      "Epoch 28/30, Train Loss: 0.8572, Train Acc: 60.08%, Test Loss: 0.8560, Test Acc: 61.25%\n",
      "Epoch 29/30, Train Loss: 0.8556, Train Acc: 60.15%, Test Loss: 0.8548, Test Acc: 61.30%\n",
      "Epoch 30/30, Train Loss: 0.8541, Train Acc: 60.31%, Test Loss: 0.8538, Test Acc: 61.30%\n",
      "\n",
      "Final Training Accuracy: 60.32%\n",
      "Final Test Accuracy: 61.30%\n",
      "\n",
      "Running iteration 12/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 128, 'batch_size': 64, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.9907, Train Acc: 50.84%, Test Loss: 0.9836, Test Acc: 52.00%\n",
      "Epoch 2/30, Train Loss: 0.9745, Train Acc: 51.95%, Test Loss: 0.9663, Test Acc: 53.40%\n",
      "Epoch 3/30, Train Loss: 0.9592, Train Acc: 53.61%, Test Loss: 0.9499, Test Acc: 55.60%\n",
      "Epoch 4/30, Train Loss: 0.9451, Train Acc: 55.01%, Test Loss: 0.9350, Test Acc: 57.40%\n",
      "Epoch 5/30, Train Loss: 0.9330, Train Acc: 55.88%, Test Loss: 0.9221, Test Acc: 57.10%\n",
      "Epoch 6/30, Train Loss: 0.9227, Train Acc: 56.68%, Test Loss: 0.9105, Test Acc: 57.65%\n",
      "Epoch 7/30, Train Loss: 0.9136, Train Acc: 57.05%, Test Loss: 0.9007, Test Acc: 58.30%\n",
      "Epoch 8/30, Train Loss: 0.9061, Train Acc: 57.67%, Test Loss: 0.8930, Test Acc: 58.70%\n",
      "Epoch 9/30, Train Loss: 0.9000, Train Acc: 57.94%, Test Loss: 0.8870, Test Acc: 58.75%\n",
      "Epoch 10/30, Train Loss: 0.8950, Train Acc: 58.17%, Test Loss: 0.8821, Test Acc: 59.35%\n",
      "Epoch 11/30, Train Loss: 0.8908, Train Acc: 58.54%, Test Loss: 0.8781, Test Acc: 59.55%\n",
      "Epoch 12/30, Train Loss: 0.8871, Train Acc: 58.61%, Test Loss: 0.8747, Test Acc: 59.70%\n",
      "Epoch 13/30, Train Loss: 0.8837, Train Acc: 58.92%, Test Loss: 0.8718, Test Acc: 59.90%\n",
      "Epoch 14/30, Train Loss: 0.8806, Train Acc: 59.12%, Test Loss: 0.8691, Test Acc: 60.05%\n",
      "Epoch 15/30, Train Loss: 0.8777, Train Acc: 59.26%, Test Loss: 0.8668, Test Acc: 60.15%\n",
      "Epoch 16/30, Train Loss: 0.8751, Train Acc: 59.36%, Test Loss: 0.8647, Test Acc: 60.15%\n",
      "Epoch 17/30, Train Loss: 0.8727, Train Acc: 59.58%, Test Loss: 0.8627, Test Acc: 60.05%\n",
      "Epoch 18/30, Train Loss: 0.8705, Train Acc: 59.60%, Test Loss: 0.8611, Test Acc: 60.05%\n",
      "Epoch 19/30, Train Loss: 0.8684, Train Acc: 59.80%, Test Loss: 0.8593, Test Acc: 60.10%\n",
      "Epoch 20/30, Train Loss: 0.8664, Train Acc: 59.93%, Test Loss: 0.8578, Test Acc: 60.20%\n",
      "Epoch 21/30, Train Loss: 0.8645, Train Acc: 59.98%, Test Loss: 0.8562, Test Acc: 60.20%\n",
      "Epoch 22/30, Train Loss: 0.8626, Train Acc: 60.08%, Test Loss: 0.8550, Test Acc: 60.20%\n",
      "Epoch 23/30, Train Loss: 0.8609, Train Acc: 60.06%, Test Loss: 0.8536, Test Acc: 60.50%\n",
      "Epoch 24/30, Train Loss: 0.8592, Train Acc: 60.17%, Test Loss: 0.8525, Test Acc: 60.50%\n",
      "Epoch 25/30, Train Loss: 0.8575, Train Acc: 60.35%, Test Loss: 0.8513, Test Acc: 60.65%\n",
      "Epoch 26/30, Train Loss: 0.8559, Train Acc: 60.41%, Test Loss: 0.8502, Test Acc: 60.65%\n",
      "Epoch 27/30, Train Loss: 0.8544, Train Acc: 60.52%, Test Loss: 0.8489, Test Acc: 60.85%\n",
      "Epoch 28/30, Train Loss: 0.8529, Train Acc: 60.63%, Test Loss: 0.8481, Test Acc: 60.55%\n",
      "Epoch 29/30, Train Loss: 0.8514, Train Acc: 60.66%, Test Loss: 0.8471, Test Acc: 60.70%\n",
      "Epoch 30/30, Train Loss: 0.8500, Train Acc: 60.70%, Test Loss: 0.8460, Test Acc: 60.80%\n",
      "\n",
      "Final Training Accuracy: 60.75%\n",
      "Final Test Accuracy: 60.80%\n",
      "\n",
      "Running iteration 13/20 with parameters: {'learning_rate': 0.01, 'hidden_size': 128, 'batch_size': 64, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8717, Train Acc: 59.73%, Test Loss: 0.8252, Test Acc: 62.50%\n",
      "Epoch 2/30, Train Loss: 0.8116, Train Acc: 63.55%, Test Loss: 0.8344, Test Acc: 62.85%\n",
      "Epoch 3/30, Train Loss: 0.7806, Train Acc: 65.60%, Test Loss: 0.8237, Test Acc: 62.60%\n",
      "Epoch 4/30, Train Loss: 0.7539, Train Acc: 66.43%, Test Loss: 0.8151, Test Acc: 63.30%\n",
      "Epoch 5/30, Train Loss: 0.7242, Train Acc: 68.58%, Test Loss: 0.8134, Test Acc: 63.50%\n",
      "Epoch 6/30, Train Loss: 0.6967, Train Acc: 69.61%, Test Loss: 0.8086, Test Acc: 64.15%\n",
      "Epoch 7/30, Train Loss: 0.6763, Train Acc: 70.98%, Test Loss: 0.8091, Test Acc: 63.95%\n",
      "Epoch 8/30, Train Loss: 0.6526, Train Acc: 72.32%, Test Loss: 0.8077, Test Acc: 65.70%\n",
      "Epoch 9/30, Train Loss: 0.6313, Train Acc: 73.31%, Test Loss: 0.8217, Test Acc: 64.10%\n",
      "Epoch 10/30, Train Loss: 0.6107, Train Acc: 74.19%, Test Loss: 0.8467, Test Acc: 62.35%\n",
      "Epoch 11/30, Train Loss: 0.5892, Train Acc: 75.40%, Test Loss: 0.7813, Test Acc: 65.60%\n",
      "Epoch 12/30, Train Loss: 0.5684, Train Acc: 76.04%, Test Loss: 0.8299, Test Acc: 63.30%\n",
      "Epoch 13/30, Train Loss: 0.5511, Train Acc: 76.93%, Test Loss: 0.9557, Test Acc: 62.90%\n",
      "Epoch 14/30, Train Loss: 0.5247, Train Acc: 78.76%, Test Loss: 0.8883, Test Acc: 63.40%\n",
      "Epoch 15/30, Train Loss: 0.5263, Train Acc: 78.67%, Test Loss: 0.8703, Test Acc: 62.65%\n",
      "Epoch 16/30, Train Loss: 0.5016, Train Acc: 79.46%, Test Loss: 0.8276, Test Acc: 65.50%\n",
      "Epoch 17/30, Train Loss: 0.4904, Train Acc: 79.85%, Test Loss: 0.9228, Test Acc: 61.55%\n",
      "Epoch 18/30, Train Loss: 0.4708, Train Acc: 80.86%, Test Loss: 0.8934, Test Acc: 61.20%\n",
      "Epoch 19/30, Train Loss: 0.4592, Train Acc: 81.37%, Test Loss: 0.8492, Test Acc: 62.35%\n",
      "Epoch 20/30, Train Loss: 0.4507, Train Acc: 81.96%, Test Loss: 0.8274, Test Acc: 64.40%\n",
      "Epoch 21/30, Train Loss: 0.4272, Train Acc: 83.02%, Test Loss: 0.8620, Test Acc: 63.70%\n",
      "Epoch 22/30, Train Loss: 0.4359, Train Acc: 82.67%, Test Loss: 0.8586, Test Acc: 64.15%\n",
      "Epoch 23/30, Train Loss: 0.4079, Train Acc: 84.22%, Test Loss: 1.2033, Test Acc: 56.70%\n",
      "Epoch 24/30, Train Loss: 0.3987, Train Acc: 84.65%, Test Loss: 1.0603, Test Acc: 57.85%\n",
      "Epoch 25/30, Train Loss: 0.3902, Train Acc: 85.17%, Test Loss: 1.0909, Test Acc: 61.35%\n",
      "Epoch 26/30, Train Loss: 0.3797, Train Acc: 85.04%, Test Loss: 1.0649, Test Acc: 59.10%\n",
      "Epoch 27/30, Train Loss: 0.3631, Train Acc: 85.71%, Test Loss: 0.8754, Test Acc: 64.60%\n",
      "Epoch 28/30, Train Loss: 0.3563, Train Acc: 86.02%, Test Loss: 0.9064, Test Acc: 63.70%\n",
      "Epoch 29/30, Train Loss: 0.3494, Train Acc: 86.70%, Test Loss: 2.4591, Test Acc: 52.30%\n",
      "Epoch 30/30, Train Loss: 0.3634, Train Acc: 86.29%, Test Loss: 0.8763, Test Acc: 64.65%\n",
      "\n",
      "Final Training Accuracy: 89.82%\n",
      "Final Test Accuracy: 64.65%\n",
      "\n",
      "Running iteration 14/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 32, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8779, Train Acc: 59.79%, Test Loss: 0.8757, Test Acc: 57.90%\n",
      "Epoch 2/30, Train Loss: 0.7839, Train Acc: 65.07%, Test Loss: 0.8124, Test Acc: 63.90%\n",
      "Epoch 3/30, Train Loss: 0.7397, Train Acc: 67.52%, Test Loss: 0.8269, Test Acc: 63.05%\n",
      "Epoch 4/30, Train Loss: 0.6920, Train Acc: 70.45%, Test Loss: 0.8066, Test Acc: 63.50%\n",
      "Epoch 5/30, Train Loss: 0.6559, Train Acc: 71.77%, Test Loss: 0.7833, Test Acc: 64.65%\n",
      "Epoch 6/30, Train Loss: 0.6246, Train Acc: 73.49%, Test Loss: 0.7902, Test Acc: 66.15%\n",
      "Epoch 7/30, Train Loss: 0.5940, Train Acc: 74.83%, Test Loss: 0.7950, Test Acc: 64.15%\n",
      "Epoch 8/30, Train Loss: 0.5604, Train Acc: 76.93%, Test Loss: 0.7948, Test Acc: 64.95%\n",
      "Epoch 9/30, Train Loss: 0.5250, Train Acc: 78.57%, Test Loss: 0.7787, Test Acc: 64.85%\n",
      "Epoch 10/30, Train Loss: 0.4973, Train Acc: 79.65%, Test Loss: 0.8289, Test Acc: 64.70%\n",
      "Epoch 11/30, Train Loss: 0.4729, Train Acc: 81.01%, Test Loss: 0.8413, Test Acc: 63.75%\n",
      "Epoch 12/30, Train Loss: 0.4461, Train Acc: 82.44%, Test Loss: 0.7946, Test Acc: 65.25%\n",
      "Epoch 13/30, Train Loss: 0.4208, Train Acc: 83.34%, Test Loss: 0.8788, Test Acc: 62.35%\n",
      "Epoch 14/30, Train Loss: 0.4004, Train Acc: 84.07%, Test Loss: 0.8266, Test Acc: 64.40%\n",
      "Epoch 15/30, Train Loss: 0.3582, Train Acc: 86.07%, Test Loss: 0.7941, Test Acc: 65.95%\n",
      "Epoch 16/30, Train Loss: 0.3345, Train Acc: 87.45%, Test Loss: 0.8153, Test Acc: 64.95%\n",
      "Epoch 17/30, Train Loss: 0.3050, Train Acc: 88.81%, Test Loss: 0.8041, Test Acc: 65.75%\n",
      "Epoch 18/30, Train Loss: 0.2910, Train Acc: 89.23%, Test Loss: 0.8484, Test Acc: 64.30%\n",
      "Epoch 19/30, Train Loss: 0.2668, Train Acc: 90.24%, Test Loss: 0.8480, Test Acc: 64.25%\n",
      "Epoch 20/30, Train Loss: 0.2469, Train Acc: 91.22%, Test Loss: 0.8586, Test Acc: 63.75%\n",
      "Epoch 21/30, Train Loss: 0.2311, Train Acc: 91.68%, Test Loss: 0.8869, Test Acc: 63.75%\n",
      "Epoch 22/30, Train Loss: 0.2209, Train Acc: 92.02%, Test Loss: 0.8846, Test Acc: 62.70%\n",
      "Epoch 23/30, Train Loss: 0.2036, Train Acc: 92.81%, Test Loss: 0.8599, Test Acc: 65.15%\n",
      "Epoch 24/30, Train Loss: 0.1868, Train Acc: 93.51%, Test Loss: 0.8763, Test Acc: 64.00%\n",
      "Epoch 25/30, Train Loss: 0.1703, Train Acc: 94.37%, Test Loss: 0.8875, Test Acc: 63.85%\n",
      "Epoch 26/30, Train Loss: 0.1622, Train Acc: 94.67%, Test Loss: 0.8568, Test Acc: 64.65%\n",
      "Epoch 27/30, Train Loss: 0.1435, Train Acc: 95.59%, Test Loss: 0.8864, Test Acc: 64.40%\n",
      "Epoch 28/30, Train Loss: 0.1357, Train Acc: 95.52%, Test Loss: 0.9089, Test Acc: 64.00%\n",
      "Epoch 29/30, Train Loss: 0.1304, Train Acc: 95.85%, Test Loss: 0.9392, Test Acc: 63.25%\n",
      "Epoch 30/30, Train Loss: 0.1201, Train Acc: 95.95%, Test Loss: 0.8815, Test Acc: 64.25%\n",
      "\n",
      "Final Training Accuracy: 97.88%\n",
      "Final Test Accuracy: 64.25%\n",
      "\n",
      "Running iteration 15/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 256, 'batch_size': 128, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.9883, Train Acc: 51.60%, Test Loss: 0.9821, Test Acc: 53.35%\n",
      "Epoch 2/30, Train Loss: 0.9795, Train Acc: 53.13%, Test Loss: 0.9728, Test Acc: 55.10%\n",
      "Epoch 3/30, Train Loss: 0.9710, Train Acc: 54.59%, Test Loss: 0.9632, Test Acc: 57.00%\n",
      "Epoch 4/30, Train Loss: 0.9622, Train Acc: 55.97%, Test Loss: 0.9538, Test Acc: 57.60%\n",
      "Epoch 5/30, Train Loss: 0.9536, Train Acc: 56.87%, Test Loss: 0.9445, Test Acc: 58.45%\n",
      "Epoch 6/30, Train Loss: 0.9453, Train Acc: 57.16%, Test Loss: 0.9355, Test Acc: 58.80%\n",
      "Epoch 7/30, Train Loss: 0.9373, Train Acc: 57.49%, Test Loss: 0.9267, Test Acc: 59.20%\n",
      "Epoch 8/30, Train Loss: 0.9298, Train Acc: 57.91%, Test Loss: 0.9185, Test Acc: 59.20%\n",
      "Epoch 9/30, Train Loss: 0.9230, Train Acc: 58.19%, Test Loss: 0.9113, Test Acc: 59.15%\n",
      "Epoch 10/30, Train Loss: 0.9171, Train Acc: 58.25%, Test Loss: 0.9044, Test Acc: 59.00%\n",
      "Epoch 11/30, Train Loss: 0.9118, Train Acc: 58.36%, Test Loss: 0.8982, Test Acc: 59.20%\n",
      "Epoch 12/30, Train Loss: 0.9072, Train Acc: 58.72%, Test Loss: 0.8931, Test Acc: 59.00%\n",
      "Epoch 13/30, Train Loss: 0.9032, Train Acc: 58.92%, Test Loss: 0.8889, Test Acc: 59.05%\n",
      "Epoch 14/30, Train Loss: 0.8998, Train Acc: 58.90%, Test Loss: 0.8852, Test Acc: 59.20%\n",
      "Epoch 15/30, Train Loss: 0.8967, Train Acc: 58.92%, Test Loss: 0.8820, Test Acc: 59.25%\n",
      "Epoch 16/30, Train Loss: 0.8941, Train Acc: 59.02%, Test Loss: 0.8792, Test Acc: 59.30%\n",
      "Epoch 17/30, Train Loss: 0.8918, Train Acc: 58.99%, Test Loss: 0.8771, Test Acc: 59.35%\n",
      "Epoch 18/30, Train Loss: 0.8897, Train Acc: 58.95%, Test Loss: 0.8752, Test Acc: 59.30%\n",
      "Epoch 19/30, Train Loss: 0.8879, Train Acc: 59.03%, Test Loss: 0.8735, Test Acc: 59.30%\n",
      "Epoch 20/30, Train Loss: 0.8862, Train Acc: 59.07%, Test Loss: 0.8721, Test Acc: 59.40%\n",
      "Epoch 21/30, Train Loss: 0.8847, Train Acc: 59.18%, Test Loss: 0.8708, Test Acc: 59.60%\n",
      "Epoch 22/30, Train Loss: 0.8832, Train Acc: 59.26%, Test Loss: 0.8694, Test Acc: 59.65%\n",
      "Epoch 23/30, Train Loss: 0.8818, Train Acc: 59.29%, Test Loss: 0.8681, Test Acc: 59.70%\n",
      "Epoch 24/30, Train Loss: 0.8804, Train Acc: 59.35%, Test Loss: 0.8670, Test Acc: 59.90%\n",
      "Epoch 25/30, Train Loss: 0.8791, Train Acc: 59.40%, Test Loss: 0.8658, Test Acc: 59.90%\n",
      "Epoch 26/30, Train Loss: 0.8778, Train Acc: 59.53%, Test Loss: 0.8648, Test Acc: 59.95%\n",
      "Epoch 27/30, Train Loss: 0.8765, Train Acc: 59.54%, Test Loss: 0.8638, Test Acc: 59.95%\n",
      "Epoch 28/30, Train Loss: 0.8754, Train Acc: 59.65%, Test Loss: 0.8628, Test Acc: 59.95%\n",
      "Epoch 29/30, Train Loss: 0.8742, Train Acc: 59.70%, Test Loss: 0.8618, Test Acc: 59.95%\n",
      "Epoch 30/30, Train Loss: 0.8731, Train Acc: 59.80%, Test Loss: 0.8610, Test Acc: 60.00%\n",
      "\n",
      "Final Training Accuracy: 59.88%\n",
      "Final Test Accuracy: 60.00%\n",
      "\n",
      "Running iteration 16/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 256, 'batch_size': 32, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.9997, Train Acc: 50.19%, Test Loss: 0.9846, Test Acc: 52.00%\n",
      "Epoch 2/30, Train Loss: 0.9647, Train Acc: 55.74%, Test Loss: 0.9472, Test Acc: 55.95%\n",
      "Epoch 3/30, Train Loss: 0.9321, Train Acc: 57.48%, Test Loss: 0.9162, Test Acc: 57.85%\n",
      "Epoch 4/30, Train Loss: 0.9084, Train Acc: 58.41%, Test Loss: 0.8981, Test Acc: 59.05%\n",
      "Epoch 5/30, Train Loss: 0.8948, Train Acc: 58.86%, Test Loss: 0.8882, Test Acc: 59.30%\n",
      "Epoch 6/30, Train Loss: 0.8871, Train Acc: 58.97%, Test Loss: 0.8821, Test Acc: 60.00%\n",
      "Epoch 7/30, Train Loss: 0.8814, Train Acc: 59.22%, Test Loss: 0.8773, Test Acc: 60.25%\n",
      "Epoch 8/30, Train Loss: 0.8768, Train Acc: 59.43%, Test Loss: 0.8734, Test Acc: 60.50%\n",
      "Epoch 9/30, Train Loss: 0.8727, Train Acc: 59.75%, Test Loss: 0.8698, Test Acc: 60.80%\n",
      "Epoch 10/30, Train Loss: 0.8689, Train Acc: 60.16%, Test Loss: 0.8670, Test Acc: 61.05%\n",
      "Epoch 11/30, Train Loss: 0.8653, Train Acc: 60.17%, Test Loss: 0.8643, Test Acc: 60.80%\n",
      "Epoch 12/30, Train Loss: 0.8618, Train Acc: 60.36%, Test Loss: 0.8620, Test Acc: 60.95%\n",
      "Epoch 13/30, Train Loss: 0.8586, Train Acc: 60.62%, Test Loss: 0.8596, Test Acc: 60.75%\n",
      "Epoch 14/30, Train Loss: 0.8555, Train Acc: 60.67%, Test Loss: 0.8577, Test Acc: 60.90%\n",
      "Epoch 15/30, Train Loss: 0.8525, Train Acc: 60.87%, Test Loss: 0.8556, Test Acc: 61.20%\n",
      "Epoch 16/30, Train Loss: 0.8497, Train Acc: 60.85%, Test Loss: 0.8536, Test Acc: 61.50%\n",
      "Epoch 17/30, Train Loss: 0.8470, Train Acc: 61.12%, Test Loss: 0.8520, Test Acc: 61.60%\n",
      "Epoch 18/30, Train Loss: 0.8444, Train Acc: 61.22%, Test Loss: 0.8505, Test Acc: 61.60%\n",
      "Epoch 19/30, Train Loss: 0.8420, Train Acc: 61.49%, Test Loss: 0.8490, Test Acc: 61.50%\n",
      "Epoch 20/30, Train Loss: 0.8396, Train Acc: 61.56%, Test Loss: 0.8477, Test Acc: 61.45%\n",
      "Epoch 21/30, Train Loss: 0.8374, Train Acc: 61.67%, Test Loss: 0.8462, Test Acc: 61.35%\n",
      "Epoch 22/30, Train Loss: 0.8351, Train Acc: 61.86%, Test Loss: 0.8448, Test Acc: 61.45%\n",
      "Epoch 23/30, Train Loss: 0.8330, Train Acc: 61.82%, Test Loss: 0.8435, Test Acc: 61.70%\n",
      "Epoch 24/30, Train Loss: 0.8310, Train Acc: 61.89%, Test Loss: 0.8425, Test Acc: 61.65%\n",
      "Epoch 25/30, Train Loss: 0.8290, Train Acc: 61.94%, Test Loss: 0.8408, Test Acc: 61.75%\n",
      "Epoch 26/30, Train Loss: 0.8271, Train Acc: 62.13%, Test Loss: 0.8400, Test Acc: 61.85%\n",
      "Epoch 27/30, Train Loss: 0.8253, Train Acc: 62.16%, Test Loss: 0.8385, Test Acc: 61.85%\n",
      "Epoch 28/30, Train Loss: 0.8234, Train Acc: 62.32%, Test Loss: 0.8375, Test Acc: 61.90%\n",
      "Epoch 29/30, Train Loss: 0.8217, Train Acc: 62.42%, Test Loss: 0.8371, Test Acc: 62.05%\n",
      "Epoch 30/30, Train Loss: 0.8199, Train Acc: 62.55%, Test Loss: 0.8357, Test Acc: 62.15%\n",
      "\n",
      "Final Training Accuracy: 62.70%\n",
      "Final Test Accuracy: 62.15%\n",
      "\n",
      "Running iteration 17/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8602, Train Acc: 60.32%, Test Loss: 0.8064, Test Acc: 64.10%\n",
      "Epoch 2/30, Train Loss: 0.7846, Train Acc: 65.33%, Test Loss: 0.7929, Test Acc: 65.00%\n",
      "Epoch 3/30, Train Loss: 0.7377, Train Acc: 67.75%, Test Loss: 0.8024, Test Acc: 63.45%\n",
      "Epoch 4/30, Train Loss: 0.7011, Train Acc: 70.03%, Test Loss: 0.7970, Test Acc: 64.15%\n",
      "Epoch 5/30, Train Loss: 0.6715, Train Acc: 71.37%, Test Loss: 0.7915, Test Acc: 64.15%\n",
      "Epoch 6/30, Train Loss: 0.6430, Train Acc: 72.61%, Test Loss: 0.7926, Test Acc: 64.45%\n",
      "Epoch 7/30, Train Loss: 0.6178, Train Acc: 73.87%, Test Loss: 0.7853, Test Acc: 65.45%\n",
      "Epoch 8/30, Train Loss: 0.5979, Train Acc: 74.95%, Test Loss: 0.8138, Test Acc: 63.40%\n",
      "Epoch 9/30, Train Loss: 0.5724, Train Acc: 76.29%, Test Loss: 0.7656, Test Acc: 65.30%\n",
      "Epoch 10/30, Train Loss: 0.5440, Train Acc: 77.57%, Test Loss: 0.7621, Test Acc: 65.65%\n",
      "Epoch 11/30, Train Loss: 0.5135, Train Acc: 79.24%, Test Loss: 0.7805, Test Acc: 65.15%\n",
      "Epoch 12/30, Train Loss: 0.4961, Train Acc: 79.96%, Test Loss: 0.7803, Test Acc: 65.25%\n",
      "Epoch 13/30, Train Loss: 0.4755, Train Acc: 81.08%, Test Loss: 0.7685, Test Acc: 65.70%\n",
      "Epoch 14/30, Train Loss: 0.4487, Train Acc: 82.59%, Test Loss: 0.7638, Test Acc: 65.10%\n",
      "Epoch 15/30, Train Loss: 0.4394, Train Acc: 82.86%, Test Loss: 0.7823, Test Acc: 66.50%\n",
      "Epoch 16/30, Train Loss: 0.4268, Train Acc: 83.29%, Test Loss: 0.7870, Test Acc: 66.00%\n",
      "Epoch 17/30, Train Loss: 0.4059, Train Acc: 84.53%, Test Loss: 0.7733, Test Acc: 66.60%\n",
      "Epoch 18/30, Train Loss: 0.3854, Train Acc: 85.44%, Test Loss: 0.7961, Test Acc: 65.00%\n",
      "Epoch 19/30, Train Loss: 0.3569, Train Acc: 86.91%, Test Loss: 0.7774, Test Acc: 67.20%\n",
      "Epoch 20/30, Train Loss: 0.3481, Train Acc: 87.02%, Test Loss: 0.7806, Test Acc: 65.75%\n",
      "Epoch 21/30, Train Loss: 0.3259, Train Acc: 88.18%, Test Loss: 0.8067, Test Acc: 65.00%\n",
      "Epoch 22/30, Train Loss: 0.3046, Train Acc: 89.09%, Test Loss: 0.8010, Test Acc: 64.30%\n",
      "Epoch 23/30, Train Loss: 0.2927, Train Acc: 89.75%, Test Loss: 0.7902, Test Acc: 65.55%\n",
      "Epoch 24/30, Train Loss: 0.2728, Train Acc: 90.67%, Test Loss: 0.7859, Test Acc: 65.55%\n",
      "Epoch 25/30, Train Loss: 0.2560, Train Acc: 91.44%, Test Loss: 0.7979, Test Acc: 64.75%\n",
      "Epoch 26/30, Train Loss: 0.2489, Train Acc: 91.47%, Test Loss: 0.7800, Test Acc: 65.60%\n",
      "Epoch 27/30, Train Loss: 0.2293, Train Acc: 92.36%, Test Loss: 0.7999, Test Acc: 64.40%\n",
      "Epoch 28/30, Train Loss: 0.2258, Train Acc: 92.46%, Test Loss: 0.7926, Test Acc: 64.85%\n",
      "Epoch 29/30, Train Loss: 0.2162, Train Acc: 92.90%, Test Loss: 0.8167, Test Acc: 64.95%\n",
      "Epoch 30/30, Train Loss: 0.1898, Train Acc: 93.94%, Test Loss: 0.7967, Test Acc: 65.85%\n",
      "\n",
      "Final Training Accuracy: 94.91%\n",
      "Final Test Accuracy: 65.85%\n",
      "\n",
      "Running iteration 18/20 with parameters: {'learning_rate': 0.01, 'hidden_size': 256, 'batch_size': 64, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 1.7738, Train Acc: 53.77%, Test Loss: 1.1194, Test Acc: 61.55%\n",
      "Epoch 2/30, Train Loss: 1.3079, Train Acc: 56.80%, Test Loss: 2.0572, Test Acc: 49.15%\n",
      "Epoch 3/30, Train Loss: 1.5263, Train Acc: 56.15%, Test Loss: 2.2525, Test Acc: 57.90%\n",
      "Epoch 4/30, Train Loss: 1.6291, Train Acc: 58.31%, Test Loss: 1.8899, Test Acc: 56.75%\n",
      "Epoch 5/30, Train Loss: 1.5315, Train Acc: 58.81%, Test Loss: 2.2510, Test Acc: 55.70%\n",
      "Epoch 6/30, Train Loss: 1.4613, Train Acc: 60.04%, Test Loss: 2.5787, Test Acc: 52.95%\n",
      "Epoch 7/30, Train Loss: 1.6641, Train Acc: 59.65%, Test Loss: 1.8558, Test Acc: 62.05%\n",
      "Epoch 8/30, Train Loss: 1.7121, Train Acc: 60.77%, Test Loss: 2.7044, Test Acc: 54.60%\n",
      "Epoch 9/30, Train Loss: 1.9319, Train Acc: 60.76%, Test Loss: 1.6515, Test Acc: 60.00%\n",
      "Epoch 10/30, Train Loss: 1.4562, Train Acc: 63.20%, Test Loss: 1.4628, Test Acc: 59.85%\n",
      "Epoch 11/30, Train Loss: 1.4606, Train Acc: 63.06%, Test Loss: 2.8162, Test Acc: 55.00%\n",
      "Epoch 12/30, Train Loss: 1.5402, Train Acc: 63.63%, Test Loss: 1.8431, Test Acc: 56.45%\n",
      "Epoch 13/30, Train Loss: 1.3440, Train Acc: 65.26%, Test Loss: 2.4855, Test Acc: 56.15%\n",
      "Epoch 14/30, Train Loss: 1.5267, Train Acc: 65.48%, Test Loss: 2.2074, Test Acc: 57.90%\n",
      "Epoch 15/30, Train Loss: 1.6143, Train Acc: 66.05%, Test Loss: 3.0922, Test Acc: 54.20%\n",
      "Epoch 16/30, Train Loss: 1.6742, Train Acc: 66.39%, Test Loss: 1.8921, Test Acc: 57.75%\n",
      "Epoch 17/30, Train Loss: 1.4425, Train Acc: 67.26%, Test Loss: 1.7207, Test Acc: 61.50%\n",
      "Epoch 18/30, Train Loss: 1.3802, Train Acc: 68.30%, Test Loss: 2.4331, Test Acc: 54.10%\n",
      "Epoch 19/30, Train Loss: 1.9339, Train Acc: 67.32%, Test Loss: 2.1174, Test Acc: 61.10%\n",
      "Epoch 20/30, Train Loss: 1.2913, Train Acc: 70.14%, Test Loss: 2.0221, Test Acc: 58.85%\n",
      "Epoch 21/30, Train Loss: 1.6788, Train Acc: 69.18%, Test Loss: 1.7765, Test Acc: 59.50%\n",
      "Epoch 22/30, Train Loss: 1.4403, Train Acc: 70.10%, Test Loss: 1.7193, Test Acc: 60.80%\n",
      "Epoch 23/30, Train Loss: 1.4415, Train Acc: 70.71%, Test Loss: 2.6203, Test Acc: 59.00%\n",
      "Epoch 24/30, Train Loss: 1.3363, Train Acc: 72.00%, Test Loss: 3.5431, Test Acc: 57.45%\n",
      "Epoch 25/30, Train Loss: 1.2589, Train Acc: 72.79%, Test Loss: 1.8390, Test Acc: 60.90%\n",
      "Epoch 26/30, Train Loss: 1.5139, Train Acc: 71.75%, Test Loss: 2.3952, Test Acc: 62.45%\n",
      "Epoch 27/30, Train Loss: 1.6442, Train Acc: 72.01%, Test Loss: 4.4686, Test Acc: 55.65%\n",
      "Epoch 28/30, Train Loss: 1.3375, Train Acc: 73.86%, Test Loss: 2.1407, Test Acc: 62.75%\n",
      "Epoch 29/30, Train Loss: 1.1791, Train Acc: 75.65%, Test Loss: 2.8347, Test Acc: 58.00%\n",
      "Epoch 30/30, Train Loss: 1.2211, Train Acc: 75.49%, Test Loss: 2.8628, Test Acc: 58.30%\n",
      "\n",
      "Final Training Accuracy: 73.98%\n",
      "Final Test Accuracy: 58.30%\n",
      "\n",
      "Running iteration 19/20 with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.8686, Train Acc: 60.08%, Test Loss: 0.8256, Test Acc: 62.55%\n",
      "Epoch 2/30, Train Loss: 0.7819, Train Acc: 65.02%, Test Loss: 0.8235, Test Acc: 63.25%\n",
      "Epoch 3/30, Train Loss: 0.7484, Train Acc: 67.33%, Test Loss: 0.7884, Test Acc: 64.50%\n",
      "Epoch 4/30, Train Loss: 0.7176, Train Acc: 69.36%, Test Loss: 0.7979, Test Acc: 65.40%\n",
      "Epoch 5/30, Train Loss: 0.6730, Train Acc: 71.13%, Test Loss: 0.7959, Test Acc: 65.15%\n",
      "Epoch 6/30, Train Loss: 0.6472, Train Acc: 72.60%, Test Loss: 0.7860, Test Acc: 65.20%\n",
      "Epoch 7/30, Train Loss: 0.6253, Train Acc: 73.62%, Test Loss: 0.8365, Test Acc: 62.10%\n",
      "Epoch 8/30, Train Loss: 0.6017, Train Acc: 74.82%, Test Loss: 0.8204, Test Acc: 62.55%\n",
      "Epoch 9/30, Train Loss: 0.5886, Train Acc: 75.54%, Test Loss: 0.7752, Test Acc: 65.65%\n",
      "Epoch 10/30, Train Loss: 0.5511, Train Acc: 77.23%, Test Loss: 0.7734, Test Acc: 65.75%\n",
      "Epoch 11/30, Train Loss: 0.5288, Train Acc: 78.48%, Test Loss: 0.7914, Test Acc: 65.35%\n",
      "Epoch 12/30, Train Loss: 0.5075, Train Acc: 79.55%, Test Loss: 0.7757, Test Acc: 65.45%\n",
      "Epoch 13/30, Train Loss: 0.4813, Train Acc: 81.00%, Test Loss: 0.7713, Test Acc: 65.30%\n",
      "Epoch 14/30, Train Loss: 0.4668, Train Acc: 81.43%, Test Loss: 0.7824, Test Acc: 65.50%\n",
      "Epoch 15/30, Train Loss: 0.4353, Train Acc: 83.00%, Test Loss: 0.8387, Test Acc: 64.00%\n",
      "Epoch 16/30, Train Loss: 0.4295, Train Acc: 83.27%, Test Loss: 0.7818, Test Acc: 65.60%\n",
      "Epoch 17/30, Train Loss: 0.3966, Train Acc: 85.08%, Test Loss: 0.7963, Test Acc: 65.80%\n",
      "Epoch 18/30, Train Loss: 0.3770, Train Acc: 85.96%, Test Loss: 0.7815, Test Acc: 65.55%\n",
      "Epoch 19/30, Train Loss: 0.3585, Train Acc: 86.67%, Test Loss: 0.8005, Test Acc: 65.55%\n",
      "Epoch 20/30, Train Loss: 0.3426, Train Acc: 87.51%, Test Loss: 0.7998, Test Acc: 64.45%\n",
      "Epoch 21/30, Train Loss: 0.3250, Train Acc: 88.16%, Test Loss: 0.8027, Test Acc: 64.55%\n",
      "Epoch 22/30, Train Loss: 0.3060, Train Acc: 89.21%, Test Loss: 0.7919, Test Acc: 65.30%\n",
      "Epoch 23/30, Train Loss: 0.2896, Train Acc: 89.74%, Test Loss: 0.7929, Test Acc: 64.75%\n",
      "Epoch 24/30, Train Loss: 0.2666, Train Acc: 90.81%, Test Loss: 0.8072, Test Acc: 65.10%\n",
      "Epoch 25/30, Train Loss: 0.2585, Train Acc: 91.45%, Test Loss: 0.7988, Test Acc: 64.35%\n",
      "Epoch 26/30, Train Loss: 0.2397, Train Acc: 91.96%, Test Loss: 0.8194, Test Acc: 63.70%\n",
      "Epoch 27/30, Train Loss: 0.2367, Train Acc: 91.89%, Test Loss: 0.8056, Test Acc: 65.40%\n",
      "Epoch 28/30, Train Loss: 0.2073, Train Acc: 93.11%, Test Loss: 0.8221, Test Acc: 64.40%\n",
      "Epoch 29/30, Train Loss: 0.2084, Train Acc: 93.43%, Test Loss: 0.8455, Test Acc: 63.25%\n",
      "Epoch 30/30, Train Loss: 0.1888, Train Acc: 94.01%, Test Loss: 0.8087, Test Acc: 65.05%\n",
      "\n",
      "Final Training Accuracy: 95.05%\n",
      "Final Test Accuracy: 65.05%\n",
      "\n",
      "Running iteration 20/20 with parameters: {'learning_rate': 0.001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Epoch 1/30, Train Loss: 0.9956, Train Acc: 57.78%, Test Loss: 0.8620, Test Acc: 60.70%\n",
      "Epoch 2/30, Train Loss: 0.8066, Train Acc: 63.69%, Test Loss: 0.8295, Test Acc: 63.40%\n",
      "Epoch 3/30, Train Loss: 0.7779, Train Acc: 65.54%, Test Loss: 0.8325, Test Acc: 63.40%\n",
      "Epoch 4/30, Train Loss: 0.7319, Train Acc: 68.01%, Test Loss: 0.8233, Test Acc: 63.20%\n",
      "Epoch 5/30, Train Loss: 0.7106, Train Acc: 69.39%, Test Loss: 0.9055, Test Acc: 61.40%\n",
      "Epoch 6/30, Train Loss: 0.6836, Train Acc: 70.33%, Test Loss: 0.9363, Test Acc: 60.80%\n",
      "Epoch 7/30, Train Loss: 0.6476, Train Acc: 72.64%, Test Loss: 0.9054, Test Acc: 61.55%\n",
      "Epoch 8/30, Train Loss: 0.6399, Train Acc: 72.90%, Test Loss: 0.8350, Test Acc: 63.55%\n",
      "Epoch 9/30, Train Loss: 0.6296, Train Acc: 73.79%, Test Loss: 0.8224, Test Acc: 64.85%\n",
      "Epoch 10/30, Train Loss: 0.5685, Train Acc: 76.19%, Test Loss: 0.9111, Test Acc: 62.90%\n",
      "Epoch 11/30, Train Loss: 0.5576, Train Acc: 76.79%, Test Loss: 0.8776, Test Acc: 62.80%\n",
      "Epoch 12/30, Train Loss: 0.5217, Train Acc: 78.00%, Test Loss: 0.8615, Test Acc: 63.65%\n",
      "Epoch 13/30, Train Loss: 0.4937, Train Acc: 79.65%, Test Loss: 0.9179, Test Acc: 62.00%\n",
      "Epoch 14/30, Train Loss: 0.4671, Train Acc: 81.04%, Test Loss: 0.8876, Test Acc: 64.00%\n",
      "Epoch 15/30, Train Loss: 0.4946, Train Acc: 80.03%, Test Loss: 0.8574, Test Acc: 63.65%\n",
      "Epoch 16/30, Train Loss: 0.4084, Train Acc: 83.88%, Test Loss: 0.9290, Test Acc: 63.05%\n",
      "Epoch 17/30, Train Loss: 0.4152, Train Acc: 83.53%, Test Loss: 0.9951, Test Acc: 61.00%\n",
      "Epoch 18/30, Train Loss: 0.4175, Train Acc: 83.39%, Test Loss: 0.9956, Test Acc: 62.20%\n",
      "Epoch 19/30, Train Loss: 0.3992, Train Acc: 84.17%, Test Loss: 0.9370, Test Acc: 64.15%\n",
      "Epoch 20/30, Train Loss: 0.3156, Train Acc: 87.58%, Test Loss: 0.9561, Test Acc: 63.25%\n",
      "Epoch 21/30, Train Loss: 0.3023, Train Acc: 87.93%, Test Loss: 1.0064, Test Acc: 62.70%\n",
      "Epoch 22/30, Train Loss: 0.3207, Train Acc: 87.77%, Test Loss: 1.0645, Test Acc: 61.40%\n",
      "Epoch 23/30, Train Loss: 0.3635, Train Acc: 86.04%, Test Loss: 0.9810, Test Acc: 62.95%\n",
      "Epoch 24/30, Train Loss: 0.2600, Train Acc: 89.90%, Test Loss: 0.9760, Test Acc: 63.60%\n",
      "Epoch 25/30, Train Loss: 0.2598, Train Acc: 89.82%, Test Loss: 1.0360, Test Acc: 61.70%\n",
      "Epoch 26/30, Train Loss: 0.2676, Train Acc: 89.88%, Test Loss: 1.0998, Test Acc: 63.20%\n",
      "Epoch 27/30, Train Loss: 0.2645, Train Acc: 89.90%, Test Loss: 1.0422, Test Acc: 62.15%\n",
      "Epoch 28/30, Train Loss: 0.1810, Train Acc: 93.32%, Test Loss: 1.0668, Test Acc: 64.10%\n",
      "Epoch 29/30, Train Loss: 0.2007, Train Acc: 92.54%, Test Loss: 1.1075, Test Acc: 63.30%\n",
      "Epoch 30/30, Train Loss: 0.2058, Train Acc: 92.26%, Test Loss: 1.0979, Test Acc: 62.30%\n",
      "\n",
      "Final Training Accuracy: 95.57%\n",
      "Final Test Accuracy: 62.30%\n",
      "\n",
      "Top 5 Hyperparameter Combinations:\n",
      "Rank 1: Test Accuracy: 65.85% with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Rank 2: Test Accuracy: 65.05% with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Rank 3: Test Accuracy: 64.65% with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 128, 'optimizer': 'Adam', 'num_epochs': 30}\n",
      "Rank 4: Test Accuracy: 64.65% with parameters: {'learning_rate': 0.01, 'hidden_size': 128, 'batch_size': 64, 'optimizer': 'SGD', 'num_epochs': 30}\n",
      "Rank 5: Test Accuracy: 64.30% with parameters: {'learning_rate': 0.0001, 'hidden_size': 512, 'batch_size': 32, 'optimizer': 'Adam', 'num_epochs': 30}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Perform random search\n",
    "best_results = random_search(hyperparameter_space, num_iterations=20, device=device)\n",
    "\n",
    "# Display top 5 results\n",
    "print(\"\\nTop 5 Hyperparameter Combinations:\")\n",
    "for i, res in enumerate(best_results[:5], 1):\n",
    "    print(f\"Rank {i}: Test Accuracy: {res['final_test_acc']*100:.2f}% with parameters: {res['params']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
